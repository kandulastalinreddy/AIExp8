import random
import math
from collections import defaultdict

class TicTacToe:
    def __init__(self):
        self.board = [" "] * 9  # 3x3 board
        self.current_player = "X"

    def make_move(self, move):
        if self.board[move] == " ":
            self.board[move] = self.current_player
            self.current_player = "O" if self.current_player == "X" else "X"
            return True
        return False

    def undo_move(self, move):
        self.board[move] = " "
        self.current_player = "O" if self.current_player == "X" else "X"

    def get_valid_moves(self):
        return [i for i in range(9) if self.board[i] == " "]

    def check_winner(self):
        winning_combinations = [
            (0, 1, 2), (3, 4, 5), (6, 7, 8),  # Rows
            (0, 3, 6), (1, 4, 7), (2, 5, 8),  # Columns
            (0, 4, 8), (2, 4, 6)               # Diagonals
        ]
        for a, b, c in winning_combinations:
            if self.board[a] == self.board[b] == self.board[c] and self.board[a] != " ":
                return self.board[a]
        return None if " " in self.board else "Draw"

    def is_game_over(self):
        return self.check_winner() is not None

    def __str__(self):
        return "\n".join([" | ".join(self.board[i:i+3]) for i in range(0, 9, 3)])

class MCTSNode:
    def __init__(self, state, parent=None):
        self.state = state
        self.parent = parent
        self.children = []
        self.visits = 0
        self.wins = 0
        self.untried_moves = state.get_valid_moves()

    def is_fully_expanded(self):
        return len(self.untried_moves) == 0

    def best_child(self, exploration_weight=1.41):
        return max(self.children, key=lambda child: 
                   (child.wins / (child.visits + 1e-6)) + 
                   exploration_weight * math.sqrt(math.log(self.visits + 1) / (child.visits + 1e-6)))

    def expand(self):
        move = self.untried_moves.pop()
        new_state = TicTacToe()
        new_state.board = self.state.board[:]
        new_state.current_player = self.state.current_player
        new_state.make_move(move)
        child_node = MCTSNode(new_state, self)
        self.children.append(child_node)
        return child_node

    def backpropagate(self, result):
        self.visits += 1
        if result == self.state.current_player:  # Reward parent if it led to a win for the current player
            self.wins += 1
        if self.parent:
            self.parent.backpropagate(result)

def mcts_search(root_state, itermax=1000):
    root_node = MCTSNode(root_state)

    for _ in range(itermax):
        node = root_node
        state = TicTacToe()
        state.board = root_state.board[:]
        state.current_player = root_state.current_player

        # Selection & Expansion
        while node.is_fully_expanded() and node.children:
            node = node.best_child()
            move = state.get_valid_moves()[0]  # Select any valid move to progress
            state.make_move(move)

        if node.untried_moves:
            node = node.expand()
            state.make_move(state.get_valid_moves()[0])

        # Simulation (random play-out)
        while not state.is_game_over():
            state.make_move(random.choice(state.get_valid_moves()))

        # Backpropagation
        winner = state.check_winner()
        node.backpropagate(winner)

    return root_node.best_child(exploration_weight=0).state  # Exploit only at the end

if __name__ == "__main__":
    game = TicTacToe()

    while not game.is_game_over():
        print(game)
        if game.current_player == "X":
            move = int(input("Enter your move (0-8): "))
            while not game.make_move(move):
                move = int(input("Invalid move. Enter again: "))
        else:
            print("AI is thinking...")
            game = mcts_search(game)
        print()

    print(game)
    print("Winner:", game.check_winner())
